<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title></title>
    <meta charset="utf-8" />
    <link href="libs/remark-css/chocolate-fonts.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css?family=Abel|Biryani|Ubuntu+Condensed|Yanone+Kaffeesatz&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: center, middle, inverse, title-slide

&lt;div&gt;
  &lt;img src = "images/logo-ime.png" height = 75px width = 75px style = "position: absolute; left: 5px; top: 5px;"&gt;
  &lt;p style = "position: absolute; font-family: Ubuntu Condensed; font-size: 20px; top: 23px; left: 50%; transform: translate(-50%, -50%);"&gt;MAT02035 - MODELOS PARA DADOS CORRELACIONADOS&lt;/p&gt;
  &lt;img src = "images/logo-ufrgs.png" height = 75px width = 97px style = "position: absolute; right: 5px; top: 5px;"&gt;
&lt;/div&gt;

&lt;h1 id="h1-capa"&gt;Modelos de Transição&lt;br&gt;(Modelos de Markov)&lt;/h1&gt;

&lt;div id = "texto-medio-esquerda"&gt; 
  &lt;h4 style = "font-family: Abel"&gt;Angelo Rosa&lt;br&gt;Camila Leuck&lt;br&gt;Gabriel Grandemagne&lt;br&gt;Raquel Rossi&lt;br&gt;Vítor Coutinho&lt;/h4&gt;
&lt;/div&gt;

&lt;div id = "texto-medio-direita"&gt; 
  &lt;h4 style = "font-family: Abel"&gt;&lt;br&gt;&lt;br&gt;Professor: Rodrigo Citton&lt;/h4&gt;
&lt;/div&gt;

&lt;div id="texto-baixo"&gt;
  &lt;p style = "font-family: Ubuntu Condensed; font-size: 20px;"&gt;Atualizado em 18 de dezembro de 2019&lt;/p&gt;
&lt;/div&gt;

---



# Definições Importantes

- Um **processo estocástico** é, de forma simplificada, um modelo matemático utilizado para analisar trajetórias (funções) de fenômenos aleatórios

- Dado um espaço de estados `\(E\)`, uma distribuição `\(\{p_i\}_{i\in E}\)` é uma matriz **markoviana** `\(P\)` e uma sucessão de variáveis aleatórias `\(\{X_n\}_{n=0,\,1,\,...}\)` é uma **cadeia de Markov** se e somente se:

&lt;p style = "text-align: center;"&gt;$$p[X_0=i_0,\,...,\,X_n=i_n]=p_{i_0}p_{i_0}i_1\,...\,p_{i_{n-1}}i_n\,\,\,\forall{n},\,\,\forall{i_1,\,...,\,i_n\in{E}}$$&lt;/p&gt;

---

# Motivação

- Modelos marginais não captam todos efeitos **intra**-indivíduos em estudos longitudinais, apesar de permitirem a especificação de uma estrutura para a matriz de covariância
  + Isto porque os métodos modelam a regressão de `\(Y\)` sobre `\(x\)` e a **associação** entre repetições
  + Não levam em conta a **distribuição** de `\(Y\)` nas repetições anteriores 
  
- Modelos de efeitos aleatórios não resolvem esta questão, pois lidam com a heterogeneidade **entre** indivíduos

- Para resolver este problema, foram desenvolvidas extensões de MLGs para descrever a distribuição condicional da resposta `\(y_{ij}\)` do indivíduo `\(i\)` no tempo `\(j\)` como uma função explícita de suas respostas nos tempos anteriores, dadas por `\(y_{ij-1},\,y_{ij-2},\,...,\,y_{i1}\)`, e das covariáveis `\(x_{ij}\)`

---

class: img-page

&lt;h1 id="h1-capa" style = "font-family: Abel; text-align: center;"&gt;Modelos de Markov&lt;/h1&gt;

&lt;i id = "img-center"&gt;&lt;img src = "images/markov-icon.png" height = 350px width = 350px&gt;&lt;/i&gt;

---

# Modelos de Markov

- Denotaremos o **histórico** do sujeito `\(i\)` no tempo `\(j\)` por:

&lt;p style = "text-align: center;"&gt;$$\mathcal{H}_{ij}=\{y_{ik},\, k = 1,\,...,\,j-1\}$$&lt;/p&gt;

- A forma geral do MLG em questão, para `\(\psi(\theta_{ij})\)` e `\(c(y_{ij},\,\phi)\)` conhecidas, é:

&lt;p style = "text-align: center;"&gt;$$f(y_{ij}|\mathcal{H}_{ij})=\mathbb{exp}\Big\{\frac{y_{ij}\theta_{ij}-\psi(\theta_{ij})}{\phi}+c(y_{ij},\,\phi)\Big\}$$&lt;/p&gt;

- A média e variância condicionais são dadas por:

&lt;p style = "text-align: center;"&gt;$$\mu_{ij}^{C}=\mathbb{E}(Y_{ij}|\mathcal{H}_{ij})=\psi'(\theta_{ij})\,\,\text{ e }\,\,v_{ij}^{C}=\mathbb{Var}(Y_{ij}|\mathcal{H}_{ij})=\psi''(\theta_{ij})\phi$$&lt;/p&gt;

- Os modelos de transição mais úteis são cadeias de Markov em que a distribuição condicional de `\(y_{ij}\)` dado `\(\mathcal{H}_{ij}\)` depende somente das `\(q\)` observações anteriores
  + Neste caso, `\(q\)` é chamado de **ordem** do modelo

---

# Modelos de Markov

- Vamos considerar modelos em que a média e variância condicionais satisfazem as equações abaixo, em que `\(h\)` e `\(v\)` são as funções de ligação e variância (**conhecidas** de acordo com a distribuição de `\(f(y_{ij}|\mathcal{H}_{ij})\)`):

&lt;p style = "text-align: center;"&gt;$$\begin{cases}h(\mu_{ij})^C=x'_{ij}\beta+\sum_{r=1}^{s}f_r(\mathcal{H}_{ij};\alpha)\text{,  para }f_r(\cdot)\text{ válidas;}\\v_{ij}^C=v(\mu_{ij}^C)\phi\end{cases}$$&lt;/p&gt;

- Expressando `\(\mu_{ij}^C\)` como função tanto de `\(x_{ij}\)` quanto de `\(y_{ij-1},\,\dots,\,y_{ij-q}\)`, estamos tratando as respostas anteriores de cada indivíduo como variáveis explicativas adicionais
  + Presumimos que o passado afeta o futuro como uma soma de `\(s\)` termos, cada um destes podendo depender de suas `\(q\)` observações anteriores
  
---

# Modelos de Markov - Exemplos

- Um modelo de regressão linear com erros autorregressivos para dados Gaussianos é um modelo markoviano, de forma:

&lt;p style = "text-align: center;"&gt;$$Y_{ij}=x'_{ij}\beta+\sum_{r=1}^{q}\alpha_r(Y_{ij-r}-x'_{ij-r}\beta)+Z_{ij}$$&lt;/p&gt;

- Neste modelo, presumimos que os `\(Z_{ij}\)` são independentes e têm distribuições Normais com médias zero

- Este é um modelo de transição com `\(h(\mu_{ij}^C)=\mu_{ij}^C\)`, `\(v(\mu_{ij}^C)=1\)` e `\(f_r=\alpha_r(y_{ij-r}-x'_{ij-r}\beta)\)`

- Notar que a observação atual, `\(Y_{ij}\)`, é função linear tanto de `\(x_{ij}\)` quanto de dos **desvios** anteriores, `\(Y_{ij-r}-x'_{ij-r}\beta,\,\,r=1,\,\dots,\,q\)`

---
# Modelos de Markov - Exemplos

- Um modelo de regressão logístico para respostas binárias pode compôr uma cadeia de Markov, como abaixo:

&lt;p style = "text-align: center;"&gt;$$\mathbb{logit}\big(\mathbb{P}(Y_{ij}=1|\mathcal{H}_{ij})\big)=x'_{ij}\beta+\alpha y_{ij-1}$$&lt;/p&gt;

- Neste modelo, têm-se `\(h(\mu_{ij}^C)=\mathbb{logit}(\mu_{ij}^C)=\mathbb{log}\Big(\frac{\mu_{ij}^C}{1-\mu_{ij}^C}\Big)\)`, `\(v(\mu_{ij}^C)=\mu_{ij}^C(1-\mu_{ij}^C)\)` e `\(f_r(\mathcal{H}_{ij},\alpha)=\alpha_ry_{ij-r},\,s=q=1\)`.

- Pode-se extendê-lo a um modelo de ordem `\(q\)`:

&lt;p style = "text-align: center;"&gt;$$\mathbb{logit}\big(\mathbb{P}(Y_{ij}=1|\mathcal{H}_{ij})\big)=x'_{ij}\beta_q+\sum_{r=1}^{q}\alpha_ry_{ij-r}$$&lt;/p&gt;

- A notação `\(\beta_q\)` indica que tanto o valor quanto interpretação dos coeficientes no vetor mudam com a ordem `\(q\)` da cadeia de Markov

---

# Modelos de Markov - Exemplos

- Com dados de contagem, pode-se ajustar um modelo log-linear onde `\(Y_{ij}|\mathcal{H}_{ij}\sim Poisson(\lambda)\)`:
  + Tomando uma cadeia de Markov de primeira ordem onde `\(f_1=\alpha\{\mathbb{log}(y^*_{ij-1})-x'_{ij-1}\beta\}\)`, sendo `\(y^*_{ij}=\mathbb{max}(y_{ij},d),\,\,0&lt;d&lt;1\)`, podemos obter:
  
&lt;p style = "text-align: center;"&gt;$$\mu_{ij}^C=\mathbb{E}(Y_{ij}|\mathcal{H}_{ij})=\mathbb{exp}(x1_{ij}\beta)\Big(\frac{y^*_{ij-1}}{\mathbb{exp}(x'_{ij-1}\beta)}\Big)^\alpha$$&lt;/p&gt;

- A constante `\(d\)` previne que `\(y_{ij-1}=0\)` vire um estado de absorção, onde `\(y_{ij-1}=0\)` força todas respostas futuras a serem zero

- Se `\(\alpha&gt;0\)`, a média `\(\mu_{ij}^C\)` cresce quando a observação anterior `\(y_{ij-1}&gt;\mathbb{exp}(x'_{ij-1}\beta)\)`
  + Se `\(\alpha&lt;0\)`, um valor mais alto no tempo `\(t_{ij-1}\)` causa um valor mais baixo em `\(t_{ij}\)`

---

# Modelos de Markov - Observação
  
- Para o modelo de regressão **linear**, pode-se formular o modelo de transição considerando `\(f_r=\alpha_r(y_{ij-r}-x'_{ij-1}\beta)\)`, o que leva a `\(\mathbb{E}(Y_{ij})=x'_{ij}\beta\,\,\,\forall q\)`

- Para os casos logístico e log-linear, é complexo formular modelos que mantenham a interpretação de `\(\beta\)` para diferentes presunções sobre a dependência temporal
  
- Então, quando `\(\beta\)` é o foco científico do estudo, deve-se examinar a sensibilidade das estimativas relevantes com relação à escolha de modelo de dependência temporal
  
---

class: img-page

&lt;h1 id="h1-capa" style = "font-family: Abel; text-align: center;"&gt;Ajustando Modelos de Transição&lt;/h1&gt;

&lt;i id = "img-center"&gt;&lt;img src = "images/fitting-icon.png" height = 350px width = 350px&gt;&lt;/i&gt;

---

# Ajustando Modelos de Transição

O método proposto para estimação do vetor de parâmetros `\(\beta\)` foi o da máxima verossimilhança. Considerando uma amostra aleatória de n observações de uma distribuição exponencial

`\(f(y_i,\theta_i,\phi)=\mathbb{exp} \Big{\{} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{\}}\)`

A função de verossimilhança é dada por

`\(L( \theta_i , \phi ,y_i) = \prod_{i=1}^{n} f(y_i, \theta_i , \phi ) = \mathbb{exp}\Big{\{}\sum_{i=1}^{n}\Big{[} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{]}\Big{\}}\)`

Cujo logaritmo é

`\(l( \theta_i , \phi ,y_i) =\sum_{i=1}^{n}\Big{\{} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{\}}\)`

---

# Ajustando Modelos de Transição

Derivando a última função vista no slide passado em relação a `\(\beta_j\)`, obtém-se a função escore

`\(U_j= \frac{\partial l}{\partial \beta_j} = \frac{\partial l}{\partial \theta_i} \frac{\partial \theta_i}{\partial \mu_i} \frac{\partial \mu_i}{\partial \eta_i} \frac{\partial \eta_i}{\partial \beta_j} = \sum_{i=1}^{n} \frac{1}{a_i(\phi)} (y_i - \mu_i) (\frac{\partial \theta_i}{\partial \eta_i}) x_{ij}\)`

Soluções aproximadas podem ser encontradas utilizando método Newton-Raphson ou método escore de Fisher, pelo método de Fisher temos:

`\(\beta^{(m+1)} = (X'W^{(m)}X)^{-1} X'W^{(m)}z^{(m)}\)`

Onde X é a matriz de especificação do modelo e W é a matriz diagonal de pesos.

---

class: img-page

&lt;h1 id="h1-capa" style = "font-family: Abel; text-align: center;"&gt;Análise de Resíduos e Diagnósticos&lt;/h1&gt;

&lt;i id = "img-center"&gt;&lt;img src = "images/residual-icon.png" height = 350px width = 350px&gt;&lt;/i&gt;

---

# Análise de Resíduos e Diagnósticos

As técnicas usadas são as mesmas dos modelos lineares clássicos, com resposta normal, tanto para as técnicas baseadas em testes de hipóteses como para as baseadas em recursos gráficos. Os resíduos mais usuais para análise e diagnósticos dos MLGs são:

1) Resíduos de Pearson generalizados

`\(r_i^{p} = \frac{y_i -\hat{\mu_i}}{\sqrt{\frac{\hat{\phi}}{\omega_i}V(\hat{\mu_i})}}\)`

Em que `\(\hat{\phi}\)` é uma estimativa consistente para o parâmetro de dispersão `\(\phi\)` e `\(\omega_i\)` são presos a priori.

---

# Análise de Resíduos e Diagnósticos

2) Resíduos de Pearson generalizados padronizados internamente

`\(r_i^{p^i} = \frac{y_i -\hat{\mu_i}}{\sqrt{\frac{\hat{\phi}}{\omega_i}V(\hat{\mu_i})}(1-h_i)}\)`

Através de estudos de simulação de Monte Carlo a distribuição de resíduos não possuí distribuição normal, mesmo para grandes amostras.

---

# Análise de Resíduos e Diagnósticos

3) Componentes do desvio padronizados internamente

`\(r_i^{D^i} = \frac{r_i^D}{\sqrt{1-h_i}}\)`

É a versão padronizada do desvio abaixo. É o mais utilizado, tendo em vista que dentre todos a distribuição do desvio padronizado é a que mais se aproxima da normal.

`\(r_i^{D} = \pm (y_i - \hat{\mu_i})\sqrt{\frac{2 \hat{\omega_i}}{\hat{\phi}}[y_i(\tilde{\theta_i} - \hat{\theta_i}) - b(\tilde{\theta_i})+b(\hat{\theta_i})]}\)`

---

class: img-page

&lt;h1 id="h1-capa" style = "font-family: Abel; text-align: center;"&gt;Dados Categóricos&lt;/h1&gt;

&lt;i id = "img-center"&gt;&lt;img src = "images/categorical-icon.png" height = 350px width = 350px&gt;&lt;/i&gt;

---

# Dados Categóricos

- Começamos com um modelo logístico para respostas binárias, tal que &lt;p style = "text-align: center;"&gt; `$$\begin {pmatrix} \pi_{00} &amp; \pi_{01} \\ \pi_{10} &amp; \pi_{11} \end{pmatrix},$$`&lt;/p&gt;
onde `\(\pi_{ab} = \mathbb{P}(Y_{ij}=b|Y_{ij-1}=a),\space a,b=0,1\)`
- Na configuração de regressão, modelamos a probabilidade da transição como função das covariáveis `\(x_{ij}=(1,x_{ij1},x_{ij2},\dots,x_{ijp})\)`. Assumimos que: &lt;p style = "text-align: center;"&gt; `$$\mathbb{logit} \space \mathbb{P}(Y_{ij}=1|Y_{ij-1}=0)=x'_{ij}\beta_0\,\,\text{ e }\,\, \mathbb{logit} \space \mathbb{P}(Y_{ij}=1|Y_{ij-1}=1)=x'_{ij}\beta_1,$$`&lt;/p&gt; onde `\(\beta_0\)` e `\(\beta_1\)` diferem.
  + Em outras palavras esse modelo assume que os efeitos das variáveis explicativas muda dependendo na resposta prévia.

---

# Dados Categóricos

- Um modelo mais coerente pode ser descrito como: &lt;p style = "text-align: center;"&gt; `$$\mathbb{logit} \space \mathbb{P}(Y_{ij}=1|Y_{ij-1}=y_{ij-1}) = x'_{ij}\beta_0 + y_{ij-1}x'_{ij}\alpha,$$`&lt;/p&gt; 

  para que `\(\beta_1=\beta_0 + \alpha\)`. A equação acima expressa duas regressões em um único modelo logístico que incluí os preditores das respostas prévias `\(y_{ij-1}\)` assim como a interação de `\(y_{ij-1}\)` com as variáveis explicativas.

- Uma vantagem desse modelo é testar quando um modelo simples se ajusta corretamente aos dados, como por exemplo podemos testar quando `\(\alpha=(\alpha_0,0)\)`, então nosso modelo `\(y_{ij-1}x'_{ij}\alpha=\alpha_0Y_{ij-1}\)` implicando que a covariância tem o mesmo efeito na resposta quando `\(y_{ij-1}=0\)` ou `\(y_{ij-1}=1\)`.

---

# Dados Categóricos

- Analogamente, observando duas prévias medições no tempos temos que `$$\mathbb{logit}\,\mathbb{P}(Y_{ij}=1|Y_{ij-2}=y_{ij-2},\,Y_{ij-1}=y_{ij-1}) \\ = x'_{ij}\beta + y_{ij-1}x'_{ij}\alpha_1+y_{ij-2}x'_{ij}\alpha_2+y_{ij-1}y_{ij-2}x'_{ij}\alpha_3$$` 

- Colocando valores diferentes para `\(y_{ij-2}\,\text{ e }\,y_{ij-1}\)` obtemos: &lt;p style = "text-align: center;"&gt; `\(\beta_{00}=\beta\)`; `\(\,\,\beta_{01}=\beta+\alpha_1\)`; `\(\,\,\beta_{10}=\beta+\alpha_2\,\,\)` e  `\(\,\,\beta_{11}=\beta+\alpha_1+\alpha_2+\alpha_3\)` &lt;/p&gt;

- Um caso importante ocorre quando não há interações entre as respostas prévias `\(y_{ij-1} \,\text{ e }\,\, y_{ij-2}\)`, assim como as variáveis explicativas, ou seja, quando todos os elementos de `\(\alpha_i\)` é zero exceto o intercepto. Nesse caso, as respostas prévias afetam a probabilidade de um desfexo positivo porém os efeitos das variáveis explicativas são os mesmos independente de suas outras medições.

---

# Dados Categóricos

- Nessa situação, devemos escolher entre modelos Markov de ordens diferentes, por exemplo, podemos começar com um modelo de terceira ordem da forma `$$\mathbb{logit}\,\mathbb{P}(Y_{ij}=1|Y_{ij-3}=y_{ij-3},Y_{ij-2}=y_{ij-2},\,Y_{ij-1}=y_{ij-1}) \\ = x'_{ij}\beta + \alpha_1y_{ij-1}+\alpha_2y_{ij-2}+\alpha_3y_{ij-3}+\alpha_4y_{ij-1}y_{ij-2} \\ +\alpha_5y_{ij-1}y_{ij-3}+\alpha_6y_{ij-2}y_{ij-3}+\alpha_7y_{ij-1}y_{ij-2}y_{ij-3}$$` 

- Um modelo de segunda ordem pode ser usado se os dados são consistentes com `\(\alpha_3=\alpha_5=\alpha_6=\alpha_7=0\)`, um modelo de primeira ordem está implicito se `\(\alpha_j=0 \text{ para } j=2,\dots,7.\)`. Com qualquer outro coeficiente de regressão, a interpretação e o valor de `\(\beta\)` (no modelo de terceira ordem) depende nas outras variáveis explicativas no modelo, em particular nas quais as respostas prévias está inclusa.

---

# Dados Categóricos

- Quando os modelos de Markov são bem especificados, os eventos de transição não são correlacionados, então podemos utilizar regressão logística para estimar os coeficientes de regressão e seus erros-padrões. Entretanto pode haver circunstâncias quando escolhemos modelar `\(\mathbb{P}(Y_{ij}\,|\,Y_{ij-1},\dots,Y_{ij-q})\)` mesmo não sendo igual à `\(\mathbb{P}(Y_{ij}\,|\,H_{ij})\)`. Por exemplo, supondo heterogeneidade entre os indivíduos na matrix de transição, um modelo rasoavel é &lt;p style = "text-align: center;"&gt; `$$\mathbb{P}(Y_{ij}=1\,|\,Y_{ij-1},\, U_i)=(\beta_0+U_i)+x'_{ij}\beta+\alpha y_{ij-1},$$`&lt;/p&gt; onde `\(U_i\)` ~ `\(N(0,\sigma^2)\)`.

---

# Dados Categóricos - Exemplo

-  Um estudo feito com crianças da indonésia a fim de mensurar o quanto a deficiência de vitamina A (indicada no banco pela presença da doença xerophtalmia) está associada com uma maior prevalência de infecções respiratórias.

- Na tabela abaixo mostramos a contagem das transições entre um estado e outro ao longo das 1200 observações, a fim de ter uma estimação das probabilidades de transição ignorando, por hora, a dependência das covariáveis explanatórias.

-Tabela 1:
&lt;img src = "images/table_Ex1.png" height = 161px width = 249px&gt;

---

# Dados Categóricos - Exemplo

- As taxas acima estimam `\(Pr(Y_{ij} |Y_{ij-1})\)`. Podemos perceber:

  + 1) Ocorreram 855 transições nas 1200 observações,
  + 2) Para crianças que não possuiam doenças respiratórias na primeira visita, **7,7%** passuiam na segunda visita, enquanto **13,5%** dos que possuíam doenças respiratórias  na primeira visita também possuiam na segunda visita.
  
- Vejamos agora a distribuição da variável resposta, dado a presença de xerophtalmia `\((X_{ij} = 1)\)`.
- Tabela 2:
&lt;img src = "images/resp_x.png" height = 171px width = 314px&gt;

---

# Dados Categóricos - Exemplo

- Podemos perceber que a proporção de crianças com deficiência de vitamina A e com infeções respiratórias é maior do que a proporção de crianças com o mesmo status e sem deficiência de vitamina A.

- A próxima tabela contém o cruzamento das informações dadas nas tabelas anteriores, a fim de ter uma maior noção do comportamento da variável resposta sob influência do status anterior `\((Y_{ij-1} = 0,1)\)` e da presença de xerophtalmia (indicador de deficiência de vitamina A).
-Tabela 3:
&lt;img src = "images/resp_x_tempo.png" height = 197px width = 381px&gt;

---

# Dados Categóricos -  Exemplo

- Com esses dados, percebemos que para o primeiro cenário, `\(Y_{ij} = 0\)` na visita anterior, a frquencia de infecção respiratória é 1.49 vezes maior entre indivíduos que apresetam xerophtalmia, enquanto no segundo cenário, `\(Y_{ij} = 1\)` na visita anterior, a proporção de indivíduos com doenças respiratórias é 1.54, assim vemos que para os dois cenários os resultados quanto ao efeito da xerophtalmia são semelhantes, embora `\(Y_{ij-1}\)` seja um bom preditor de `\(Y_{ij}\)`.

  + Dado as análises exploratórias, sugerimos um modelo logit `\(Pr(Y_{ij}=1|Y_{ij-1}=y_{ij-1}) = x_{ij} \beta + \alpha y_{ij-1}\)`

- Ajustamos modelos utilizando as variáveis mostradas anteriormente e alguns resultados são abordados na tabela a seguir,
a tabela também contém informações de modelos utilizando outras covariáveis.

---

# Dados Categóricos -  Exemplo
- Tabela 4:
&lt;img src = "images/tabela_coefs.png" height = 498px width = 522px&gt;

---

# Dados Categóricos -  Exemplo

- Modelo 1) A tabela contém o coeficiente da regressão, o erro padrão definido por procedimentos comuns de regressão logística e o erro padrão robusto. O primeiro modelo leva em conta apenas a presença de Xerophtalmia e suas estimações devem reproduzir a Tabela 2. Percebam que a frequencia de crianças sem xerophtalmia com infecções respiratórias é **8,0%** = `\(\text{exp}\frac{(-2.44)}{[1+exp(-2.44)]}\)`. Calculando o log odds ratio da Tabela 2 obetmos: `\(log\Bigg[\frac{(0.119/0.881)}{(0.080/0.920)}\,\Bigg]=0.44,\)` que é o coeficiente da variável xerophtalmia na tabela 4

---

# Dados Categóricos -  Exemplo

- Modelo 2) Contém uma análise que vê a diferença na associação de xerophtalmia e doenças respiratórias quanto a presença de doenças respiratórias na visita anterior do indivíduo e deve reproduzir as taxas de transição da Tabela 3.

  + Olhando para as crianças sem infecção respiratória o log odds ratio para xerophtalmia é igual ao coeficiente para xerophtlamia (atual visita) no modelo 2 `\((log[(0.108/0.892)/(0.075/0.925] = 0.40)\)`. Assim, o log odds ratio para crianças com infecção na visita aterior será 0.40 + 0.11= 0.51 (efeito de `\(xerophtalmia + infecçao*xerophtalmia\)` na visita anterior)

---

# Dados Categóricos -  Exemplo

- Quando comparamos a Tabela 2 com Tabela 3 obtemos indícios que o efeito de xerophtalmia é similar entre os indivíduos que pussuíam ou não infecção na visita anterior, os resultados do modelo 2 nos confirmam isso, afinal, temos que o IC95 para o coeficiente da interação `\(infecção*xerophtalmia\)` é (-2.1 ;2.3), inclusive, essa interação foi retirada no modelo 3.

  + Os modelos anteriores ilustram bem regressões logísticas ajustadas a cadeias de markov simples, tal formulação nos permite adicionar com facilidade covariáveis ao modelo, assim, vemos os efeitos ao adicionar as variáveis idade e um indicador dicotômico de temporada, (1 = 2º quadrimestre, 0 = Outro).

---

# Dados Categóricos -  Exemplo

- Modelo 4: Foi ajustado um modelo com todas as variáveis descritas e suas interações  com `\(Y_{ij-1}\)` (seria o mesmo que calcular regressões separadas para os casos em que `\(Y_{ij-1} = 0, 1\)`). Como nenhuma das interações teve importância, elas foram retiradas no Modelo 5.

- Em modelos de transição é importante checar o quanto as inferências da regressão sobre `\(\beta\)` mudam em conjunto com a dependência da variável resposta com o tempo. Assim, para ilustrar, vamos apresentar os resultados quando adicionamos `\(Y_{ij-2}\)` ao Modelo 5:

  + 1) A influência de `\(Y_{ij-1}\)` e da Temporada diminui.
  + 2) O coeficiente de xerophtalmia aumenta para 1.73, aproximadamente o dobro do coeficinete no modelo 5.

---

# Dados Categóricos -  Exemplo

- Assim, mostramos uma importante propriedade dos modelos de transição: As variáveis explicativas e as respostas anteriores são tratadas simetricamente como preditores da variável resposta, desse modo, as interpretações quanto as variáveis explicativas vão mudar quando a influência das respostas antriores sofrerem mudanças. É interessante checar a sensitividade do efeito das covariáveis quanto à diferentes modelos com dependência de tempo.

---

# Dados Categóricos Ordenados

- Para formular um modelo de transição para dados categóricos ordenados, dizemos que `\(Y_{ij}\)` indica a variável resposta que contém `\(C\)` valores de categorias ordenadas, chamadas `\(0,1,\dots,C-1.\)` Um exemplo comum de dados categóricos ordenados seria um escore de saúde, como: ruim, médio, bom e exelente.
- A matriz de primeira ordem para `\(Y_{ij}\)` é definida por `\(\pi_{ab}=\mathbb{P}(Y_{ij}=b\,|\,Y_{ij-1}=a) \text{  para } a,b=0,1,\dots,C-1.\)` Com dados binários `\((C=2)\)`, um modelo saturado da matriz de transição pode ser obtido ajustando uma regressão separadamente para cada possível valor `\(C\)` de `\(Y_{ij}-1\)`, ou seja, modelamos `\(\mathbb{P}(Y_{ij}=b\,|\,Y_{ij-1}=a)\)` separadamente para cada `\(a=0,1,\dots,C-1.\)`

---

# Dados Categóricos Ordenados

- Queremos encontrar um modelo de regressão cujo coeficientes tem a mesma interpretação quando nós combinamos ou separamos as categorias, então trabalhamos com a probabilidade acumulada `\(\mathbb{P}(Y\le a).\)` Com as probabilidades acumuladas, podemos derivar a célula de probabilidades pois `\(\mathbb{P}(Y\le a)=\mathbb{P}(Y\le a-1)+\mathbb{P}(Y= a),\, a=1,\dots,C-1.\)` O modelo de razão para observações independentes se dá por &lt;p style = "text-align: center;"&gt; `$$\text{logit}\,\mathbb{P}(Y\le a)=\text{log}\frac{\mathbb{P}(Y\le a)}{\mathbb{P}(Y&gt; a)}=\theta_a+x'\beta,$$` &lt;/p&gt;
onde `\(a=0,1,\dots,C-2.\)` Daqui em diante iremos escrever o intercepto do modelo como `\(\theta_a\)` e não iremos incluir um intercepto em termos de `\(x\)`.

---

# Dados Categóricos Ordenados

- O parâmetro de regressão `\(\beta\)` possuí uma interpretação de seu log razão de chances, pois &lt;p style = "text-align: center;"&gt;$$\frac{\mathbb{P}(Y\le a\,|\,x_1)/\mathbb{P}(Y&gt;a\,|\,x_1)}{\mathbb{P}(Y\le a\,|\,x_2)/\mathbb{P}(Y&gt;a\,|\,x_2)}=\text{exp }\{(x_1-x_2)'\beta\}$$&lt;/p&gt;

- É conveniente introduzir o vetor de variáveis `\(Y^*=(Y_0^*,Y_1^*,\dots,Y_{C-2}^*)\)` definido por `\(Y_a^*=1,\)` se `\(Y\le a\)` e 0 caso contrário. O modelo proporcional de chance é a regressão logística para `\(Y_a^*\)`, pois &lt;p style = "text-align: center;"&gt;$$\text{log}\,\frac{\mathbb{P}(Y\le a)}{\mathbb{P}(Y&gt;a)}=\text{logit}\,\mathbb{P}(Y_a^*=1)=\theta_a+x'\beta,\,\, a=0,1,\dots,C-2.$$&lt;/p&gt;
  + Nossa primeira aplicação é o modelo saturado de primeira ordem sem as covariáveis. A matriz de transição é dada por `\(\mathbb{P}(Y_{ij}=b\,|\,Y_{ij-1}=a),\, a=0,1,\dots,C-1\)`

---

# Dados Categóricos Ordenados

- Modelando as probabilidades acumuladas, `\(\mathbb{P}(Y_{ij}\le b \,|\, Y_{ij-1}=a)=\pi_{a0}+\pi_{a1}+\dots+\pi_{ab},\)` assumindo que `\(\text{log}\frac{\mathbb{P}(Y_{ij}\le b \,|\, Y_{ij-1}=a)}{\mathbb{P}(Y_{ij}&gt; b \,|\, Y_{ij-1}=a)}=\theta_{ab}\)`
onde `\(a=0,1,\dots,C-1\)` e `\(b=0,1,\dots,C-2.\)` Agora supondo que as covariáveis `\(x_{ij}\)` acarretam diferentes efeitos em `\(Y_{ij}\)` para cada observação prévia `\(Y_{ij-1}\)` o modelo pode ser descrito como `\(\text{log}\frac{\mathbb{P}(Y_{ij}\le b \,|\, Y_{ij-1}=a)}{\mathbb{P}(Y_{ij}&gt; b \,|\, Y_{ij-1}=a)}=\theta_{ab}+x'_{ij}\beta_a\)`

---

# Dados Categóricos Ordenados

Também podemos escrever o modelo acima como uma única (talvez complcada) equação de regressão 

&lt;img src = "images/feqt.png" height = 101px width = 316px&gt;

Com a formulação acima, podemos ver se o efeito das covariáveis muda em relação as categorias de `\(Y_{ij-1}\)`
  testando se `\(\gamma_a = 0\)`

O modelo de regressão ordinal de transição pode  ser estimado usando máxima verossimilhança condicional, isso é, condicionando cada indiídua à sua primeira resposta.

---

class: img-page

&lt;h1 id="h1-capa" style = "font-family: Abel; text-align: center;"&gt;Dados de Contagem&lt;/h1&gt;

&lt;i id = "img-center"&gt;&lt;img src = "images/counting-icon.png" height = 350px width = 350px&gt;&lt;/i&gt;

---

# Dados de Contagem

- Vamos considerar extensões do modelo log-linear no qual o distribuição condicional de `\(y_{ij}\)` dado o passado `\(H_{ij}\)` é Poisson com expectativas condicionais  que depende tanto dos resultados passados `\(y_{i1},\dots,y_{ij-1}\)` quanto das variáveis explicativas `\(x_{ij}\)`. Começamos analisando três modelos possíveis para a média condicional `\(\mu_{ij}^C\)` . Em cada caso, restringimos nossa atenção a uma cadeia Markov de primeira ordem.
 
---

# Dados de Contagem

- 1) `\(\mu_{ij}^C=\text{exp}(x'_{ij}\beta)\{1+\text{exp}(-\alpha_0-\alpha_1 y_{ij-1})\},\,\alpha_0,\alpha_1&gt;0\)`

  + Nesse modelo, `\(\beta\)`  representa a influência das variáveis explicativas quando a resposta anterior assume o valor `\(y_{ij-1}=0.\)` Quando `\(y_{ij-1}&gt;0\)` a expectativa condicional diminui de seu máximo valor, `\(\text{exp}(x'_{ij}\beta)\{1+\text{exp}(-\alpha_0)\},\)`  em uma quantidade que depende de `\(\alpha_1,\)` portanto este modelo permite apenas uma associação negativa entre as respostas anteriores e atuais. Para um dado `\(\alpha_0\)`, o grau de correlação negativa  aumenta à medida que `\(\alpha_1\)` aumenta. Observe que a expectativa condicional deve variar entre `\(\text{exp}(x'_{ij}β)\)` e duas vezes esse valor, como conseqüência das restrições em `\(\alpha_0\)` e `\(\alpha_1\)`.

---

# Dados de Contagem

- 2) `\(\mu_{ij}^C=\text{exp}(x'_{ij}\beta+\alpha y_{ij-1})\)`

  + Este modelo parece sensível por analogia com o modelo logístico. Mas tem aplicação limitada para dados de contagem porque quando `\(\alpha&gt;0,\)` a expectativa condicional cresce como uma função exponencial do tempo. De fato, quando `\(\text{exp}(x'_{ij}\beta)=\mu,\)` correspondendo a nenhuma dependência de covariáveis, essa suposição leva a um processo estacionário somente quando `\(\alpha&gt;0\)`. Portanto, o modelo pode descrever associação negativa
mas não associação positiva sem crescer exponencialmente ao longo do tempo.


---

# Dados de Contagem

- 3) `\(\mu_{ij}^C=\text{exp}[x'_{ij}\beta+\alpha\{\text{log}(y_{ij-1}^*)-x'_{ij-1}\beta\}], \text{ onde } y_{ij-1}^*=\text{max}(y_{ij-1},\,d)\)`

  + Quando `\(\alpha=0,\)` reduz para um modelo log-linear comum. Quando `\(\alpha&lt;0,\)` uma resposta anterior maior que sua expectativa diminui a expectativa para a resposta atual e há correlação negativa entre `\(y_{ij-1} \text{ e } y_{ij}.\)` Quando `\(\alpha&gt;0,\)` existe correlação positiva.

---

# Dados de Contagem

- Agora iremos focar no terceiro modelo de transição de Poisson acima. Pode surgir através do  processo de ramificação dependente do tamanho.

&lt;p style = "text-align: center;"&gt;$$y_j=\sum_{k=1}^{y_{j-1}}Z_k(y_{j-1})$$&lt;/p&gt;

A figura no próximo slide mostra cinco realizações desse modelo de transição para diferentes
valores de `\(\alpha\)`

---

# Dados de Contagem

&lt;img src = "images/Capturar1.png" height = 500px width = 400px&gt;

---

# Dados de Contagem

- Quando `\(\alpha&lt;0,\)` os caminhos da amostra oscilam para frente e para trás sobre o nível médio de longo prazo, pois um grande resultado ao mesmo tempo diminui
a expectativa condicional da próxima resposta.

- Quando `\(\alpha&gt;0,\)` o processo serpenteia, permanecendo abaixo da média de longo prazo por longos períodos.

  + Observe que os caminhos da amostra têm picos mais acentuados e vales mais amplos. Este padrão contrasta com os      caminhos de amostra autoregressivos gaussianos para os quais os picos e vales têm a mesma forma.

---

# Dados de Contagem

- No modelo de Poisson, a variância condicional é igual à média condicional. Quando por acaso temos uma observação grande, a média condicional e a variância do próximo valor são ambos grandes; isto é, o processo se torna instável e rapidamente cai em direção a média de longo prazo. 

  + Após um pequeno resultado, a média e a variância condicionais são pequenas; portanto, o processo tende a ser mais estável. Portanto, existem vales mais amplos e picos mais nítidos.

---

class: img-page

&lt;h1 id="h1-capa" style = "font-family: Abel; text-align: center;"&gt;Modelando no R&lt;/h1&gt;

&lt;i id = "img-center"&gt;&lt;img src = "images/rstudio-logo.png" height = 350px width = 350px&gt;&lt;/i&gt;

---

# Modelando no R

---

# Conclusões

---

# Agradecimentos

---

# Referências e Link Úteis
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
