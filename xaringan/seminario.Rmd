---
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    css: ["chocolate-fonts", "styles.css"]
    seal: false
    includes:
      in_header: fonts.html
---

class: center, middle, inverse, title-slide

<div>
  <img src = "images/logo-ime.png" height = 75px width = 75px style = "position: absolute; left: 5px; top: 5px;">
  <p style = "position: absolute; font-family: Ubuntu Condensed; font-size: 20px; top: 23px; left: 50%; transform: translate(-50%, -50%);">MAT02035 - MODELOS PARA DADOS CORRELACIONADOS</p>
  <img src = "images/logo-ufrgs.png" height = 75px width = 97px style = "position: absolute; right: 5px; top: 5px;">
</div>

<h1 id="h1-capa">Modelos de Transição<br>(Modelos de Markov)</h1>

<div id = "texto-medio-esquerda"> 
  <h4 style = "font-family: Abel">Angelo Rosa<br>Camila Leuck<br>Gabriel Grandemagne<br>Raquel Rossi<br>Vítor Coutinho</h4>
</div>

<div id = "texto-medio-direita"> 
  <h4 style = "font-family: Abel"><br><br>Professor: Rodrigo Citton</h4>
</div>

<div id="texto-baixo">
  <p style = "font-family: Ubuntu Condensed; font-size: 20px;">Atualizado em `r Sys.setlocale('LC_ALL', 'Portuguese_Brazil.1252'); format(Sys.Date(), format = '%d de %B de %Y')`</p>
</div>

---

```{r prep, include=FALSE}
# Opções do knitr/rmarkdown/xaringan:
options(htmltools.dir.version = FALSE)

# Libraries:
ler_libs <- function(packages){
  instalar <- packages[!(packages %in% installed.packages()[, "Package"])]
  
  if(length(instalar) > 0){
    install.packages(pkgs = instalar, dependencies = TRUE)
  }
  invisible(sapply(packages, require, character.only = TRUE))
}

ler_libs(packages = c('leaflet', 'DT'))

# Bases de dados:

```

# Introdução

- Os modelos marginais não são suficientes para descrever toda informação de estudos longitudinais, apesar de permitirem a especificação de uma estrutura par a matriz de covariância
  + Isto porque não captam todos os efeitos intra-indivíduos

- Uma solução é considerar no modelo a dependência entre a observação de cada indivíduo amostrado em determinado tempo com suas observações passadas

- Neste seminário, consideraremos extensões de MLGs para descrever a distribuição condicional da resposta $y_{ij}$ do indivíduo $i$ no tempo $j$ como uma função explícita de suas respostas nos tempos anteriores, dadas por $y_{ij-1},\,y_{ij-2},\,...,\,y_{i1}$, e das covariáveis $\textbf{x}_{ij}$

---

# Definições Importantes

- Um **processo estocástico** é, de forma simplificada, um modelo matemático utilizado para analisar trajetórias (funções) de fenômenos aleatórios

- Uma **cadeia de Markov** 

---

# Modelos de Markov

- Denotaremos o histórico do sujeito $i$ no tempo $j$ por $\mathcal{H}_{ij}=\{y_{ik},\, k = 1,\,...,\,j-1\}$

- Os modelos de transição mais úteis são cadeias de Markov em que a distribuição condicional de $y_{ij}$ dado $\mathcal{H}_{ij}$ depende somente das $q$ observações anteriores
  + Neste caso, $q$ é chamado de **ordem** do modelo

---

# Estimação dos parâmetros do MLG
O método proposto para estimação do vetor de parâmetros $\beta$ foi o da máxima verossimilhança. Considerando uma amostra aleatória de n observações de uma distribuição exponencial

$f(y_i,\theta_i,\phi)=\mathbb{exp} \Big{\{} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{\}}$

A função de verossimilhança é dada por

$L( \theta_i , \phi ,y_i) = \prod_{i=1}^{n} f(y_i, \theta_i , \phi ) = \mathbb{exp}\Big{\{}\sum_{i=1}^{n}\Big{[} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{]}\Big{\}}$

Cujo logaritmo é

$l( \theta_i , \phi ,y_i) =\sum_{i=1}^{n}\Big{\{} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{\}}$

---

# Estimação dos parâmetros do MLG

Derivando a última função vista no slide passado em relação a $\beta_j$, obtém-se a função escore

$U_j= \frac{\partial l}{\partial \beta_j} = \frac{\partial l}{\partial \theta_i} \frac{\partial \theta_i}{\partial \mu_i} \frac{\partial \mu_i}{\partial \eta_i} \frac{\partial \eta_i}{\partial \beta_j} = \sum_{i=1}^{n} \frac{1}{a_i(\phi)} (y_i - \mu_i) (\frac{\partial \theta_i}{\partial \eta_i}) x_{ij}$

Soluções aproximadas podem ser encontradas utilizando método Newton-Raphson ou método escore de Fisher, pelo método de Fisher temos:

$\beta^{(m+1)} = (X'W^{(m)}X)^{-1} X'W^{(m)}z^{(m)}$

Onde X é a matriz de especificação do modelo e W é a matriz diagonal de pesos.

---

# Análise de resíduos e diagnósticos
As técnicas usadas são as mesmas dos modelos lineares clássicos, com resposta normal, tanto para as técnicas baseadas em testes de hipóteses como para as baseadas em recursos gráficos. Os resíduos mais usuais para análise e diagnósticos dos MLGs são:

1) Resíduos de Pearson generalizados

$r_i^{p} = \frac{y_i -\hat{\mu_i}}{\sqrt{\frac{\hat{\phi}}{\omega_i}V(\hat{\mu_i})}}$

Em que $\hat{\phi}$ é uma estimativa consistente para o parâmetro de dispersão $\phi$ e $\omega_i$ são presos a priori.

---

# Análise de resíduos e diagnósticos

2) Resíduos de Pearson generalizados padronizados internamente

$r_i^{p^i} = \frac{y_i -\hat{\mu_i}}{\sqrt{\frac{\hat{\phi}}{\omega_i}V(\hat{\mu_i})}(1-h_i)}$

Através de estudos de simulação de Monte Carlo a distribuição de resíduos não possuí distribuição normal, mesmo para grandes amostras.

---

# Análise de resíduos e diagnósticos

3) Componentes do desvio padronizados internamente

$r_i^{D^i} = \frac{r_i^D}{\sqrt{1-h_i}}$

É a versão padronizada do desvio abaixo. É o mais utilizado, tendo em vista que dentre todos a distribuição do desvio padronizado é a que mais se aproxima da normal.

$r_i^{D} = \pm (y_i - \hat{\mu_i})\sqrt{\frac{2 \hat{\omega_i}}{\hat{\phi}}[y_i(\tilde{\theta_i} - \hat{\theta_i}) - b(\tilde{\theta_i})+b(\hat{\theta_i})]}$

---

# Dados binários

- Começamos com um modelo logístico para respostas binárias, tal que <p style = "text-align: center;"> $$\begin {pmatrix} \pi_{00} & \pi_{01} \\ \pi_{10} & \pi_{11} \end{pmatrix},$$</p>
onde $\pi_{ab} = \mathbb{P}(Y_{ij}=b|Y_{ij-1}=a),\space a,b=0,1$
- Na configuração de regressão, modelamos a probabilidade da transição como função das covariáveis $x_{ij}=(1,x_{ij1},x_{ij2},\dots,x_{ijp})$. Assumimos que: <p style = "text-align: center;"> $$\mathbb{logit} \space \mathbb{P}(Y_{ij}=1|Y_{ij-1}=0)=x'_{ij}\beta_0\,\,\text{ e }\,\, \mathbb{logit} \space \mathbb{P}(Y_{ij}=1|Y_{ij-1}=1)=x'_{ij}\beta_1,$$</p> onde $\beta_0$ e $\beta_1$ diferem.
  + Em outras palavras esse modelo assume que os efeitos das variáveis explicativas muda dependendo na resposta prévia.

---

# Modelos de Transição - dados categóricos

- Um modelo mais coerente pode ser descrito como: <p style = "text-align: center;"> $$\mathbb{logit} \space \mathbb{P}(Y_{ij}=1|Y_{ij-1}=y_{ij-1}) = x'_{ij}\beta_0 + y_{ij-1}x'_{ij}\alpha,$$</p> 

  para que $\beta_1=\beta_0 + \alpha$. A equação acima expressa duas regressões em um único modelo logístico que incluí os preditores das respostas prévias $y_{ij-1}$ assim como a interação de $y_{ij-1}$ com as variáveis explicativas.

- Uma vantagem desse modelo é testar quando um modelo simples se ajusta corretamente aos dados, como por exemplo podemos testar quando $\alpha=(\alpha_0,0)$, então nosso modelo $y_{ij-1}x'_{ij}\alpha=\alpha_0Y_{ij-1}$ implicando que a covariância tem o mesmo efeito na resposta quando $y_{ij-1}=0$ ou $y_{ij-1}=1$.

  + Testando se o $\alpha$ está perto de 0, indica que a covariavel associada pode ser descartada do modelo.

---

# Modelos de Transição - dados categóricos

- Analogamente, observando duas prévias medições no tempos temos que $$\mathbb{logit}\,\mathbb{P}(Y_{ij}=1|Y_{ij-2}=y_{ij-2},\,Y_{ij-1}=y_{ij-1}) \\ = x'_{ij}\beta + y_{ij-1}x'_{ij}\alpha_1+y_{ij-2}x'_{ij}\alpha_2+y_{ij-1}y_{ij-2}x'_{ij}\alpha_3$$ 

- Colocando valores diferentes para $y_{ij-2}\,\text{ e }\,y_{ij-1}$ obtemos: <p style = "text-align: center;"> $\beta_{00}=\beta$; $\beta_{01}=\beta+\alpha_1$; $\beta_{10}=\beta+\alpha_2$ e  $\beta_{11}=\beta+\alpha_1+\alpha_2+\alpha_3$ </p>

---

# Exemplos

---

# Conclusões

---

# Agradecimentos

---

# Referências e Link Úteis
