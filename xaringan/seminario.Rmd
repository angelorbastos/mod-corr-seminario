---
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    css: ["chocolate-fonts", "styles.css"]
    seal: false
    includes:
      in_header: fonts.html
---

class: center, middle, inverse, title-slide

<h3 style = "font-family: Abel; vertical-align: top;">UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL</h4>

<h1 id="h1-capa">Seminário:<br/>Modelos de Transição</h1>

<h1 id="h1-capa">Modelos para Dados Correlacionados (MAT02035)</h1>

<h3 style = "font-family: Abel;">Angelo Rosa, Camila Leuck, Gabriel dos Santos, Raquel Rossi e Vítor Coutinho</h3>

<h4 style = "font-family: Abel;">Atualizado em `r Sys.setlocale('LC_ALL', 'Portuguese_Brazil.1252'); format(Sys.Date(), format = '%d de %B de %Y')`</h2>

---

```{r prep, include=FALSE}
# Opções do knitr/rmarkdown/xaringan:
options(htmltools.dir.version = FALSE)

# Libraries:
ler_libs <- function(packages){
  instalar <- packages[!(packages %in% installed.packages()[, "Package"])]
  
  if(length(instalar) > 0){
    install.packages(pkgs = instalar, dependencies = TRUE)
  }
  invisible(sapply(packages, require, character.only = TRUE))
}

ler_libs(packages = c('leaflet', 'DT'))

# Bases de dados:

```

# Motivação

Nos estudos de dados longitudinais em que medidas são tomadas repetidamente sobre o mesmo indivíduo ao longo do tempo, há uma variação entre observações registradas entre indivíduos e dentro de um indivíduo.

Quando os estudos são desenvolvidos considerando que a variável resposta não tem distribuição normal, geralmente a metodologia adequada para a análise é usar modelos lineares generalizados (MLGs).

Os modelos de transição ou modelos de Markov, são aqueles nos quais qualquer resposta numa sequência de medidas repetidas é modelada condicionalmente sob um ou mais conjuntos de medições passadas. Basicamente caracterizam-se por apresentar uma relação de dependência da distribuição condicional da resposta atual sobre as respostas anteriores e as variáveis explicativas.
---

# Estimação dos parâmetros do MLG
O método proposto para estimação do vetor de parâmetros $\beta$ foi o da máxima verossimilhança. Considerando uma amostra aleatória de n observações de uma distribuição exponencial

$f(y_i,\theta_i,\phi)=\mathbb{exp} \Big{\{} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{\}}$

A função de verossimilhança é dada por

$L( \theta_i , \phi ,y_i) = \prod_{i=1}^{n} f(y_i, \theta_i , \phi ) = \mathbb{exp}\Big{\{}\sum_{i=1}^{n}\Big{[} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{]}\Big{\}}$

Cujo logaritmo é

$l( \theta_i , \phi ,y_i) =\sum_{i=1}^{n}\Big{\{} \frac{1}{a_i(\phi)}\big{[}y_i \theta_i - b(\theta_i)\big{]}+c(y_i,\phi) \Big{\}}$

---

# Estimação dos parâmetros do MLG

Derivando a última função vista no slide passado em relação a $\beta_j$, obtém-se a função escore

$U_j= \frac{\partial l}{\partial \beta_j} = \frac{\partial l}{\partial \theta_i} \frac{\partial \theta_i}{\partial \mu_i} \frac{\partial \mu_i}{\partial \eta_i} \frac{\partial \eta_i}{\partial \beta_j} = \sum_{i=1}^{n} \frac{1}{a_i(\phi)} (y_i - \mu_i) (\frac{\partial \theta_i}{\partial \eta_i}) x_{ij}$

Soluções aproximadas podem ser encontradas utilizando método Newton-Raphson ou método escore de Fisher, pelo método de Fisher temos:

$\beta^{(m+1)} = (X'W^{(m)}X)^{-1} X'W^{(m)}z^{(m)}$

Onde X é a matriz de especificação do modelo e W é a matriz diagonal de pesos.

---

# Análise de resíduos e diagnósticos
As técnicas usadas são as mesmas dos modelos lineares clássicos, com resposta normal, tanto para as técnicas baseadas em testes de hipóteses como para as baseadas em recursos gráficos. Os resíduos mais usuais para análise e diagnósticos dos MLGs são:

1) Resíduos de Pearson generalizados

$r_i^{p} = \frac{y_i -\hat{\mu_i}}{\sqrt{\frac{\hat{\phi}}{\omega_i}V(\hat{\mu_i})}}$

Em que $\hat{\phi}$ é uma estimativa consistente para o parâmetro de dispersão $\phi$ e $\omega_i$ são presos a priori.

---

# Análise de resíduos e diagnósticos

2) Resíduos de Pearson generalizados padronizados internamente

$r_i^{p^i} = \frac{y_i -\hat{\mu_i}}{\sqrt{\frac{\hat{\phi}}{\omega_i}V(\hat{\mu_i})}(1-h_i)}$

Através de estudos de simulação de Monte Carlo a distribuição de resíduos não possuí distribuição normal, mesmo para grandes amostras.

---

# Análise de resíduos e diagnósticos

3) Componentes do desvio padronizados internamente

$r_i^{D^i} = \frac{r_i^D}{\sqrt{1-h_i}}$

É a versão padronizada do desvio abaixo. É o mais utilizado, tendo em vista que dentre todos a distribuição do desvio padronizado é a que mais se aproxima da normal.

$r_i^{D} = \pm (y_i - \hat{\mu_i})\sqrt{\frac{2 \hat{\omega_i}}{\hat{\phi}}[y_i(\tilde{\theta_i} - \hat{\theta_i}) - b(\tilde{\theta_i})+b(\hat{\theta_i})]}$

---

# Contextualização

---

# Modelos de Transição

---

# Modelando no R

---

# Exemplos

---

# Conclusões

---

# Agradecimentos

---

# Referências Bibliográficas
